# -*- coding: utf-8 -*-
#+STARTUP: overview indent inlineimages
#+TITLE:       Laboratory Notebook for a Multi-Threaded Version of Quicksort
#+AUTHOR:      Arnaud Legrand
#+LANGUAGE:    en
#+TAGS: IMPORTANT(i) TEST(t) DEPRECATED(d) noexport(n)

* Project Overview
This project aims at providing an efficient multi-threaded
implementation of the QuickSort algorithm on multi-core machines. This
document contains my attempts to evaluate the performance of an
implementation of such code.
* General Organization
** src/
This directory comprises the parallel implementation and a standard
Makefile to compile it.
** data/
This is where raw experimental data should go. Each directory entry
comprises a set of experiments and the directory name is based on the
machine name and on the date. For example:
#+begin_src sh :results output :exports both 
echo mkdir data/`hostname`_`date +%F`
#+end_src

#+RESULTS:
: mkdir data/sama_2014-10-13

* Typical usage
** Compilation
A simple makefile with various compilation options is provided in the
src/ directory. Compilation is thus done by running the following command:
#+begin_src sh :results output :exports both 
make -C src/
#+end_src

#+RESULTS:
: make: Entering directory '/home/alegrand/Work/Documents/Enseignements/M2R_Eval_Perf_13/M2R-ParallelQuicksort/src'
: cc   -g -Wall -Wshadow -Wcast-align -Waggregate-return -Wmissing-prototypes -Wmissing-declarations -Wstrict-prototypes -Wmissing-prototypes -Wmissing-declarations -Wmissing-noreturn -Wpointer-arith -Wwrite-strings -finline-functions -O0 -pthread -lrt -std=c99  -c -o parallelQuicksort.o parallelQuicksort.c
: cc   -g -Wall -Wshadow -Wcast-align -Waggregate-return -Wmissing-prototypes -Wmissing-declarations -Wstrict-prototypes -Wmissing-prototypes -Wmissing-declarations -Wmissing-noreturn -Wpointer-arith -Wwrite-strings -finline-functions -O0 -pthread -lrt -std=c99  parallelQuicksort.o  -o parallelQuicksort 
: make: Leaving directory '/home/alegrand/Work/Documents/Enseignements/M2R_Eval_Perf_13/M2R-ParallelQuicksort/src'

** Running the code
The code is quite simple at the moment and can be run in the following way:
#+begin_src
./src/parallelQuicksort [1000000]
#+end_src
When run, the code executes initializes an array of the size given in
argument (1000000 by default) with random integer values and sorts it
using:
1. a custom sequential implementation;
2. a custom parallel implementation;
3. the libc qsort function.
Times are reported in seconds.
* Experimental Reports
** 2014-10-13
*** Initial code design
- I obtained an initial implementation from
  http://sc12.supercomputing.org/hpceducator/PythonForParallelism/codes/parallelQuicksort.c.
  According to the header, the original author is Joshua Stough from
  Washington and Lee University. I hope he will not mind that I reuse
  this piece of code for educational purposes.
- Here is a typical first execution on my laptop (an Intel(R) Core(TM)
  i7 running a Debian with Linux 3.14.15):
  #+begin_src sh :results output :exports both 
    ./src/quicksort
  #+end_src

  #+RESULTS:
  : Sequential quicksort took: 0.231571 sec.
  : at loc 506315, 5.068226e-01 < 5.068269e-01 
  : Oops, lyst did not get sorted by parallelQuicksort.
  : Parallel quicksort took: 0.161259 sec.
  : Built-in qsort took: 0.241568 sec.

  Sweet, in my first attempt, it looks like this parallel version is
  indeed running faster than then sequential one. I have to say this
  warning message is stressing me a bit though.
- On smaller instances, the code would segfault. So I reindented the
  code and thanks to valgrind and gdb, I could find what was wrong. I
  also renamed the file so that compiling is more convenient. This
  fixed the previous warning message so now everything seems fine:
  #+begin_src sh :results output :exports both 
    ./src/parallelQuicksort
  #+end_src

  #+RESULTS:
  : Sequential quicksort took: 0.239347 sec.
  : Parallel quicksort took: 0.176365 sec.
  : Built-in quicksort took: 0.244716 sec.

*** First series of experiments
Let's try to see how the three algorithms behave when changing the 
array size. Since one measurement is not enough, I run the code 5
times in a row.
#+begin_src sh foo :results output :exports both :tangle scripts/run_benchmarking.sh
  OUTPUT_DIRECTORY=data/`hostname`_`date +%F`
  mkdir -p $OUTPUT_DIRECTORY
  OUTPUT_FILE=$OUTPUT_DIRECTORY/measurements_`date +%R`.txt

  touch $OUTPUT_FILE
  for i in 100 1000 10000 100000 1000000; do
      for rep in `seq 1 5`; do
          echo "Size: $i" >> $OUTPUT_FILE;
          ./src/parallelQuicksort $i >> $OUTPUT_FILE;
      done ;
  done
#+end_src
I obtained the following [[file:data/sama_2014-10-13/measurements_03_47.txt][output]].

*** A simple plot with R
Here is a simple script to parse the results:
#+begin_src perl :results output raw :exports both :tangle scripts/csv_quicksort_extractor.pl
  use strict;

  my($line);
  my($size);

  print "Size, Type, Time\n" ;
  while($line=<>) {
      chomp $line;
      if($line =~/^Size: ([\d\.]*)$/) {
          $size = $1;
          next;
      } 
      if($line =~/^(.*) quicksort.*: ([\d\.]*) sec.$/) {
          print "$size, \"$1\", $2\n" ;
          next;
      } 
  }
#+end_src

I can then simply parse my data with the following command:

#+begin_src sh :results output :exports both 
perl scripts/csv_quicksort_extractor.pl < data/sama_2014-10-13/measurements_03\:47.txt > data/sama_2014-10-13/measurements_03\:47.csv
#+end_src

#+RESULTS:

#+begin_src R :results output graphics :file data/sama_2014-10-13/measurements_03:47.png :exports both :width 600 :height 400 :session
  df <- read.csv("data/sama_2014-10-13/measurements_03:47.csv",header=T)
  plot(df$Size,df$Time,col=c("red","blue","green")[df$Type])
#+end_src

#+RESULTS:
[[file:data/sama_2014-10-13/measurements_03_47.png]]

Well, this is not particularly nice and some may not know/like R.
*** A simple plot with gnuplot
So let's try to parse in an other way and use gnuplot:

#+begin_src perl :results output raw :exports both :tangle scripts/csv_quicksort_extractor2.pl
  use strict;

  my($line);
  my($size);
  my($seq,$par,$libc);
  print "Size, Seq, Par, Libc\n" ;
  while($line=<>) {
      chomp $line;
      if($line =~/^Size: ([\d\.]*)$/) {
          $size = $1;
          next;
      } 
      if($line =~/^Sequential quicksort.*: ([\d\.]*) sec.$/) {
          $seq=$1; next;
      } 
      if($line =~/^Parallel quicksort.*: ([\d\.]*) sec.$/) {
          $par=$1; next;
      } 
      if($line =~/^Built-in quicksort.*: ([\d\.]*) sec.$/) {
          $libc=$1; 
          print "$size, $seq, $pqr, $libc\n";
          next;
      }
  }
#+end_src

#+begin_src sh :results output raw :exports both 
  FILENAME="data/sama_2014-10-13/measurements_03:47"
  perl scripts/csv_quicksort_extractor2.pl < "$FILENAME.txt" > "${FILENAME}_wide.csv"
  echo "
    set terminal png size 600,400 
    set output '${FILENAME}_wide.png'
    set datafile separator ','
    set key autotitle columnhead
    plot '${FILENAME}_wide.csv' using 1:2 with linespoints, '' using 1:3 with linespoints, '' using 1:4 with linespoints
  " | gnuplot
  echo [[file:${FILENAME}_wide.png]]
#+end_src

#+RESULTS:
[[file:data/sama_2014-10-13/measurements_03_47_wide.png]]

Well, I'm not sure it is nicer but I have lines. A first crude
analysis seems to reveal the the parallel version is worth it for
arrays larger than 400000.

** 2021-11-18
*** Notes
- If working on Windows, generated data files need to be renamed (: not accepted in filenames).
- Current experimental setting is not good for representation (1e6 too far from other points), but log scale is not good as we lose point of intersection
- We can add more data points, but why there is not an intersection anymore? It also happens if experiments are performed more times...
- Let's increase the size, for example up to 1 billion. Intersection as a certain point!
- We may plot linear regression line
- Be careful of reading CSV, there is a space

Following experiments are run on an Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz. Windows 11 is the main OS on the machines, parallel quicksort is compiled
and executed on Ubuntu 20.04, running in the Windows Linux Subsystem with 4 GB of RAM.

Possible contributions for the performances of the program are reported in the following fishbone diagram (Ishikawa diagram).
[[file:data\fishbone.png]]

R code for plotting can be found in [[file:plot.R][plot.R]].

*** First test (5 runs per size), show confidence interval
[[file:data\LAPTOP-126V4913_2021-11-18\measurements_14_59.png]]

*** Test on more vector sizes, with 20 runs per size
[[file:data\LAPTOP-126V4913_2021-11-18\measurements_16_02.png]]

*** Linear regression
[[file:data\LAPTOP-126V4913_2021-11-18\measurements_16_02_regr.png]]

** 2021-11-24
Benchmarking script is reimplemented in Python, with the objective of randomizing chosen vector size and reduce the effect of possible fluctuations.
In addition, it automatically creates the CSV file in long format.
Program is recompiled with the maximum optimization level.

Benchmarking script can be run with:
#+begin_src sh :results output :exports both 
python3 scripts/run_benchmarking.py
#+end_src

To be tested after stopping all other applications and networks...
